{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "0.Prepare"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22d5d296f7ad6927"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-07T07:18:58.308647200Z",
     "start_time": "2026-02-07T07:18:58.308647200Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import rich\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer, models, trainers\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.normalizers import NFKC\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_device(verbose: bool = False):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        if verbose:\n",
    "            print(\"Using GPU\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        if verbose:\n",
    "            print(\"Using Apple Silicon GPU\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if verbose:\n",
    "            print(\"Using CPU\")\n",
    "    return device\n",
    "\n",
    "def clear_cuda():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "        \n",
    "def tensor_to_device(*tensors, device=\"cpu\", non_blocking=True):\n",
    "    moved = tuple(t.to(device, non_blocking=non_blocking) for t in tensors)\n",
    "    return moved if len(moved) > 1 else moved[0]\n",
    "\n",
    "\n",
    "def print_color(text: str, color: str = \"green\"):\n",
    "    rich.print(f\"[{color}]{text}[/{color}]\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-07T07:18:59.069200Z",
     "start_time": "2026-02-07T07:18:59.019225800Z"
    }
   },
   "id": "7ba160a9530ad6f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.Transformer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bfe09f37a735a74"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1Model Config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a62654b4374f302"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    vocab_size: int = 10_000\n",
    "    max_seq_len: int = 128\n",
    "\n",
    "    d_model: int = 512\n",
    "    d_ff: int = 2048\n",
    "    num_heads: int = 8\n",
    "    num_layers: int = 6\n",
    "    dropout: float = 0.1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-07T07:40:05.897728400Z",
     "start_time": "2026-02-07T07:40:05.897728400Z"
    }
   },
   "id": "9911ad572fe3fe38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.2Word Embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "febf6a44fa128b17"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class WordEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size:int, embed_size:int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        return self.embedding(x)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-07T07:46:18.701458500Z",
     "start_time": "2026-02-07T07:46:18.697461800Z"
    }
   },
   "id": "30669526b29b7243"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.3Position Embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7566b123146697c1"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, config:ModelConfig):\n",
    "        super().__init__()\n",
    "        pos_index = torch.arange(0, config.max_seq_len)\n",
    "        div_term = torch.exp(torch.arange(0, config.d_model,2) * -(math.log(10000.0))/config.d_model)\n",
    "        \n",
    "        pe = torch.zeros(config.max_seq_len, config.d_model).float()\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(pos_index.outer(div_term))\n",
    "        pe[:, 1::2] = torch.cos(pos_index.outer(div_term))\n",
    "        \n",
    "        pe = pe.unsqueeze(0) # Shape: (1, max_seq_len, embed_size)\n",
    "        self.register_buffer(\"pe\", pe, persistent=False)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        seq_len = x.size(1)\n",
    "        return self.pe[:, :seq_len, :] # Shape: (1, seq_len, embed_size)\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-07T08:53:36.023585200Z",
     "start_time": "2026-02-07T08:53:36.007848700Z"
    }
   },
   "id": "fc710b58fcba6d16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.4Layer Normalization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d3e84fb7d60efef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim:int, eps:float=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps=eps\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "        self.beta = nn.Parameter(torch.zeros(dim))\n",
    "        \n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, keepdim=True, unbiased=False)\n",
    "        \n",
    "        x_hat = (x-mean)/torch.sqrt(var+self.eps)\n",
    "        \n",
    "        return self.gamma*x_hat+self.beta\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "690c33cc2bbafaef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.5Feed Forward Network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d15f9b8f04271ebf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(config.d_model, config.d_ff)\n",
    "        self.fc2 = nn.Linear(config.d_ff, config.d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dd63e653d29cc39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.6Multi Head Attention"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdb34c229b4462a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config:ModelConfig, is_causal=False):\n",
    "        super().__init__()\n",
    "        self.num_heads = config.num_heads\n",
    "        self.head_dim = config.d_model // config.num_heads\n",
    "        self.is_causal = is_causal\n",
    "        \n",
    "        self.q_proj = nn.Linear(config.d_model, config.d_model)\n",
    "        self.k_proj = nn.Linear(config.d_model, config.d_model)\n",
    "        self.v_proj = nn.Linear(config.d_model, config.d_model)\n",
    "        \n",
    "        self.out_proj = nn.Linear(config.d_model, config.d_model)\n",
    "        \n",
    "        \n",
    "    def construct_mask(self, pad_mask, q_len:int, k_len:int, device):\n",
    "        #\"True for valid positions, False for masked positions\"\n",
    "        mask = None\n",
    "        \n",
    "        # causal mask (decoder self-attention only)\n",
    "        if self.is_causal:\n",
    "            mask = torch.tril(torch.ones((q_len,k_len),device=device,dtype=torch.bool))[None, None,:,:]\n",
    "            \n",
    "        if pad_mask is not None:\n",
    "            key_valid = (~pad_mask.bool())[:,None,None,:]\n",
    "            mask = key_valid if mask is None else (mask & key_valid)\n",
    "        \n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        device = q.device\n",
    "        b, q_len, _ = q.shape\n",
    "        _, kv_len,_ = k.shape\n",
    "        mask = self.construct_mask(mask, q_len, kv_len, device)\n",
    "        \n",
    "        q = self.q_proj(q).view(b,q_len,self.num_heads,self.head_dim).transpose(1,2)\n",
    "        k = self.k_proj(k).view(b,kv_len,self.num_heads,self.head_dim).transpose(1,2)\n",
    "        v = self.v_proj(v).view(b,kv_len,self.num_heads,self.head_dim).transpose(1,2)\n",
    "        \n",
    "        logits = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(self.head_dim)\n",
    "        \n",
    "        if mask is not None:\n",
    "            logits = logits.masked_fill(~mask,float(\"-inf\"))\n",
    "            \n",
    "        score = F.softmax(logits,dim=-1)\n",
    "        attn_output = torch.matmul(score,v)\n",
    "        attn_output = einops.rearrange(attn_output,\"batch heads seq_len d_k -> batch seq_len (heads d_k)\",)\n",
    "        \n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        \n",
    "        return attn_output\n",
    "            \n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a2b4208986ca05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.7Encoder Block"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "707ceead36fa7463"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, config:ModelConfig):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = MultiHeadAttention(config, is_causal=False)\n",
    "        self.ln1 = LayerNorm(config.d_model)\n",
    "        \n",
    "        self.ffn = FFN(config)\n",
    "        self.ln2 = LayerNorm(config.d_model)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor, mask=None)->torch.Tensor:\n",
    "        attn_output = self.attn(x,x,x,mask=mask) # this means self attention\n",
    "        x = self.ln1(x+attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.ln2(x+ffn_output)\n",
    "        \n",
    "        return x\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9678e3b501cdeda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.8Decoder Block"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "924a8e7858c393cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, config:ModelConfig):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(config, is_causal=False)\n",
    "        self.ln1 = LayerNorm(config.d_model)\n",
    "        \n",
    "        self.cross_attn = MultiHeadAttention(config, is_causal=True)\n",
    "        self.ln2 = LayerNorm(config.d_model)\n",
    "        \n",
    "        self.ffn = FFN(config)\n",
    "        self.ln3 = LayerNorm(config.d_model)\n",
    "        \n",
    "    def forward(\n",
    "            self, \n",
    "            x:torch.Tensor, \n",
    "            enc_output:torch.Tensor, \n",
    "            src_mask=None, \n",
    "            tgt_mask=None)->torch.Tensor:\n",
    "        self_attn_output = self.self_attn(x,x,x,mask=tgt_mask)\n",
    "        x = self.ln1(x+self_attn_output)\n",
    "        \n",
    "        cross_attn_output = self.cross_attn(x,enc_output,enc_output,mask=src_mask)\n",
    "        x = self.ln2(x+cross_attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.ln3(x+ffn_output)\n",
    "        \n",
    "        return x\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa71261e2322d4bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.9Encoder and Decoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80b42005e46ae9a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config:ModelConfig):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderBlock(config) for _ in range(config.num_layers)])\n",
    "        \n",
    "    def forward(self, x:torch.Tensor, mask=None)->torch.Tensor:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,mask)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config:ModelConfig):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([DecoderBlock(config) for _ in range(config.num_layers)])\n",
    "        \n",
    "    def forward(\n",
    "            self,\n",
    "            x:torch.Tensor,\n",
    "            enc_output:torch.Tensor,\n",
    "            src_mask=None,\n",
    "            tgt_mask=None)->torch.Tensor:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,enc_output,src_mask,tgt_mask)\n",
    "        return x\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "839715e0cccd3bfd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.10Full Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c7ff7a906ceb31e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config:ModelConfig):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_embedding = WordEmbedding(config.vocab_size, config.d_model)\n",
    "        self.positional_embedding = PositionalEmbedding(config)\n",
    "        \n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "        \n",
    "        self.output_proj = nn.Linear(config.d_model, )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42017ff07b4789ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
